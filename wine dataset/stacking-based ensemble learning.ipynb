{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad7be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d235313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset and split into training and testing sets\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.20, random_state=46)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0729d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train set shpae -  (142, 13)\n",
      "y train set shpae -  (142,)\n",
      "X test set shpae -  (36, 13)\n",
      "y test set shpae -  (36,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train set shpae - \",X_train.shape)\n",
    "print(\"y train set shpae - \",y_train.shape)\n",
    "print(\"X test set shpae - \",X_test.shape)\n",
    "print(\"y test set shpae - \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4e548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d1b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base models\n",
    "knn = KNeighborsClassifier(n_neighbors=90)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "svc = SVC(C=1, gamma=0.1, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7070fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the number of folds for cross-validation\n",
    "num_folds = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a29194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train several base models on the K-1 folds and use them to make predictions on the Kth fold\n",
    "kf = KFold(n_splits=num_folds)\n",
    "base_models = [rf, dt, knn]\n",
    "base_predictions = np.zeros((X_train.shape[0], len(base_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf39d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 1., 2.],\n",
       "       [0., 0., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 2.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 2.],\n",
       "       [1., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, model in enumerate(base_models):\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "        X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        base_predictions[val_idx, i] = model.predict(X_val_fold)\n",
    "        \n",
    "base_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931dd333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train a meta-model on the predictions from step 3\n",
    "meta_model = svc\n",
    "meta_model.fit(base_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f0aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Repeat steps 3-4 for all K folds\n",
    "meta_predictions = np.zeros((X_test.shape[0], len(base_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3b01a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 2.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 2., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 2.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [2., 2., 2.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [2., 1., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, model in enumerate(base_models):\n",
    "    model.fit(X_train, y_train)\n",
    "    meta_predictions[:, i] = model.predict(X_test)\n",
    "\n",
    "meta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88620d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 0, 0, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Use the meta-model to make predictions on the testing data\n",
    "final_predictions = meta_model.predict(meta_predictions)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db998a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115e715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the performance of the stacking model\n",
    "accuracy = accuracy_score(y_test, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294d2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Essemble Model Accuracy =  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"Stacking Essemble Model Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6200074",
   "metadata": {},
   "source": [
    "# Much Effecient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
